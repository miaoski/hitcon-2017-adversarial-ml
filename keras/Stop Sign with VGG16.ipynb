{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [[('n06794110', 'street_sign', 0.75948793), ('n06874185', 'traffic_light', 0.067035221), ('n03891332', 'parking_meter', 0.055802993), ('n03710193', 'mailbox', 0.048303321), ('n03670208', 'limousine', 0.0098589566)]]\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "model = VGG16(include_top=True, weights='imagenet')\n",
    "\n",
    "img_path = 'stopsign-1.png'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "print('Predicted:', decode_predictions(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ./fake-stop-signs/1.png\n",
      "Predicted: ('n06794110', 'street_sign', 0.71284908)\n",
      "('n04443257', 'tobacco_shop', 0.076942407)\n",
      "('n02791270', 'barbershop', 0.073321424)\n",
      "('n02977058', 'cash_machine', 0.034629501)\n",
      "('n02776631', 'bakery', 0.022398459)\n",
      "File: ./fake-stop-signs/2.png\n",
      "Predicted: ('n06794110', 'street_sign', 0.88551289)\n",
      "('n04443257', 'tobacco_shop', 0.040456396)\n",
      "('n02791270', 'barbershop', 0.017940043)\n",
      "('n02977058', 'cash_machine', 0.010459026)\n",
      "('n02776631', 'bakery', 0.0094476277)\n",
      "File: ./fake-stop-signs/3.png\n",
      "Predicted: ('n06794110', 'street_sign', 0.64636403)\n",
      "('n04443257', 'tobacco_shop', 0.13456982)\n",
      "('n02791270', 'barbershop', 0.032843452)\n",
      "('n02977058', 'cash_machine', 0.026793456)\n",
      "('n07248320', 'book_jacket', 0.013603142)\n",
      "File: ./fake-stop-signs/4.png\n",
      "Predicted: ('n06794110', 'street_sign', 0.61454618)\n",
      "('n02776631', 'bakery', 0.035764601)\n",
      "('n04443257', 'tobacco_shop', 0.025784584)\n",
      "('n02791270', 'barbershop', 0.018410504)\n",
      "('n04462240', 'toyshop', 0.016930871)\n",
      "File: ./fake-stop-signs/5.png\n",
      "Predicted: ('n06794110', 'street_sign', 0.83467817)\n",
      "('n02776631', 'bakery', 0.023134328)\n",
      "('n06874185', 'traffic_light', 0.022127202)\n",
      "('n04443257', 'tobacco_shop', 0.018259609)\n",
      "('n04149813', 'scoreboard', 0.0069144573)\n",
      "File: ./fake-stop-signs/6.png\n",
      "Predicted: ('n06794110', 'street_sign', 0.65049529)\n",
      "('n03710193', 'mailbox', 0.11415682)\n",
      "('n02747177', 'ashcan', 0.036159534)\n",
      "('n02843684', 'birdhouse', 0.031476885)\n",
      "('n02977058', 'cash_machine', 0.025805002)\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "for fn in glob('./fake-stop-signs/*.png'):\n",
    "    print('File:', fn)\n",
    "    img = image.load_img(fn, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    preds = model.predict(x)\n",
    "    print('Predicted:', '\\n'.join([repr(x) for x in decode_predictions(preds)[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
